---
layout:     post
title:      视频 微博
date:       2020-10-17
author:     Tangle
catalog: true
tags:
    - 视频
---

# 下载脚本

0. <https://github.com/dataabc/weibo-crawler>
0. 源码安装
    ```
    git clone https://github.com/dataabc/weibo-crawler.git
    pip install -r requirements.txt
    ```

# 程序设置

0. <https://github.com/dataabc/weibo-crawler#3%E7%A8%8B%E5%BA%8F%E8%AE%BE%E7%BD%AE>
0. conf.json 文件
    ```
    {
        "user_id_list": ["1669879400"],     # 微博的id
        "user_id_list": "user_id_list.txt", # 微博的id
        "filter": 1,                        # 值为0代表爬取全部微博（原创+转发）
        "since_date": "2018-01-01",         # since_date值可以是日期，也可以是整数。如果是日期，代表爬取该日期之后的微博
        "write_mode": ["csv"],              # 控制结果文件格式
        "original_pic_download": 1,         # 控制是否下载原创微博中的图片，值为1代表下载，值为0代表不下载
        "retweet_pic_download": 0,          # 控制是否下载转发微博中的图片
        "original_video_download": 1,       # 控制是否下载原创微博中的视频和原创微博Live Photo中的视频
        "retweet_video_download": 0,        # 控制是否下载转发微博中的视频和转发微博Live Photo中的视频
        "cookie": "your cookie",            # cookie 可选
        "mysql_config": {                   # 如果你不需要将结果信息写入mysql，这个参数可以忽略
            "host": "localhost",
            "port": 3306,
            "user": "root",
            "password": "123456",
            "charset": "utf8mb4"
        }
    }
    ```
    
## My conf.json

```
# conf.json
{
    "user_id_list": "user_id_list.txt",
    "filter": 0,
    "since_date": "2018-01-01",
    "write_mode": ["csv"],
    "original_pic_download": 0,
    "retweet_pic_download": 0,
    "original_video_download": 0,
    "retweet_video_download": 1,
    "cookie": "your cookie",
}
```

```
# user_id_list.txt
1223178222 胡歌
1669879400 迪丽热巴
1729370543 郭碧婷
```

# 运行程序

```
python weibo.py
```

# 按需求修改脚本

0. <https://github.com/dataabc/weibo-crawler#6%E6%8C%89%E9%9C%80%E6%B1%82%E4%BF%AE%E6%94%B9%E8%84%9A%E6%9C%AC%E5%8F%AF%E9%80%89>
