---
layout:     post
title:      视频 微博
date:       2020-10-17
author:     Tangle
catalog: true
tags:
    - 视频
---

# 下载脚本

0. <https://github.com/dataabc/weibo-crawler>
0. 源码安装
    ```
    git clone https://github.com/dataabc/weibo-crawler.git
    pip install -r requirements.txt
    ```

# 程序设置

0. <https://github.com/dataabc/weibo-crawler#3%E7%A8%8B%E5%BA%8F%E8%AE%BE%E7%BD%AE>
0. conf.json 文件
    ```
    {
        "user_id_list": ["1669879400"],     # 微博的id
        "user_id_list": "user_id_list.txt", # 微博的id
        "filter": 1,                        # 值为0代表爬取全部微博（原创+转发）
        "since_date": "2018-01-01",         # since_date值可以是日期，也可以是整数。如果是日期，代表爬取该日期之后的微博
        "write_mode": ["csv"],              # 控制结果文件格式
        "original_pic_download": 1,         # 控制是否下载原创微博中的图片，值为1代表下载，值为0代表不下载
        "retweet_pic_download": 0,          # 控制是否下载转发微博中的图片
        "original_video_download": 1,       # 控制是否下载原创微博中的视频和原创微博Live Photo中的视频
        "retweet_video_download": 0,        # 控制是否下载转发微博中的视频和转发微博Live Photo中的视频
        "cookie": "your cookie",            # cookie 可选
        "mysql_config": {                   # mysql 可选
            "host": "localhost",
            "port": 3306,
            "user": "root",
            "password": "123456",
            "charset": "utf8mb4"
        }
    }
    ```
    
## My conf.json

```
# conf.json
{
    "user_id_list": "user_id_list.txt",
    "filter": 0,
    "since_date": "2018-01-01",
    "write_mode": ["csv"],
    "original_pic_download": 0,
    "retweet_pic_download": 0,
    "original_video_download": 0,
    "retweet_video_download": 1,
    "cookie": "your cookie"
}
```

```
# user_id_list.txt
1223178222 胡歌
1669879400 迪丽热巴
1729370543 郭碧婷
```

# 运行程序

```
python weibo.py
```

# 按需求修改脚本

<https://github.com/dataabc/weibo-crawler#6%E6%8C%89%E9%9C%80%E6%B1%82%E4%BF%AE%E6%94%B9%E8%84%9A%E6%9C%AC%E5%8F%AF%E9%80%89>

## 函数

```
main                                    # 主函数
    get_config                          # 获取config.json文件信息
    Weibo                               # Weibo类
        __init__                        # Weibo类初始化
            validate_config             # 验证配置是否正确
                is_date                 # 判断日期格式是否正确
            get_user_config_list        # 获取文件中的微博id信息
    start                               # 运行爬虫
        initialize_info                 # 初始化爬虫信息
        update_user_config_file         # 更新用户配置文件
        get_pages                       # 获取全部微博
            get_user_info               # 获取用户信息
            print_user_info             # 打印用户信息
            initialize_info             # 初始化爬虫信息
            get_page_count              # 获取微博页数
                get_one_page            # 获取一页的全部微博
                    get_weibo_json      # 获取网页中微博json数据
                    print_weibo         # 打印微博，若为转发微博，会同时打印原创和转发部分
                        print_one_weibo # 打印一条微博
            write_data                  # 将爬到的信息写入文件或数据库
                write_csv               # 将爬到的信息写入csv文件
                    get_write_info      # 获取要写入的微博信息
                    get_result_headers  # 获取要写入结果文件的表头
                    csv_helper          # 将指定信息写入csv文件
                write_json              # 将爬到的信息写入json文件
                    update_json_data    # 更新要写入json结果文件中的数据，已经存在于json中的信息更新为最新值，不存在的信息添加到data中
                weibo_to_mysql          # 将爬取的微博信息写入MySQL数据库
                weibo_to_mongodb        # 将爬取的微博信息写入MongoDB数据库
                download_files          # 下载文件(图片/视频)
                    get_filepath        # 获取结果文件路径
```

## 修改

```
file_prefix # 文件前缀
if page %   # 每爬20页写入一次文件
urls, w     # w 是视频信息
```

```
# 文件前缀
file_prefix = w['created_at'][:11].replace('-', '') + '_' + str(w['id']) # 日期 + id
file_prefix_1 = str(w['id']) + '_' + str(w['text'])                      # id + 标题
```

## 定期自动爬取微博

```
# user_id_list.txt

1223178222 胡歌 2020-01-18 # 2020-01-18 到现在的全部微博
1227368500 杨紫 2018-01-23 # 2018-01-23 到现在的全部微博
```

# 输出

```
def handle_download(self, file_type, file_dir, urls, w):
    print(w) # OrderedDict([('user_id', 1223178222), ('screen_name', '胡歌'), ('id', 4537530756111575), ('bid', 'JfKltpDTN'), ('text', '聆听沉默背后的“星”动守护，和#Giorgio Armani#一起成为七夕爱的朗读者。@Armani阿玛尼 网页链接armanichina的优酷视频 '), ('article_url', ''), ('pics', ''), ('video_url', 'https://api.youku.com/videos/player/file?data=WcEl5oEuYdzVOakF4TVRZNE5BPT18MHwxfDEwMDUwfDAO0O0O'), ('location', ''), ('created_at', '2020-08-13'), ('source', 'HUAWEI Mate Xs 5G'), ('attitudes_count', 230967), ('comments_count', 46463), ('reposts_count', 106374), ('topics', 'Giorgio Armani'), ('at_users', 'Armani阿玛尼')])
    
def 
```
